{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a85970f",
   "metadata": {},
   "source": [
    "# Dictionary example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8610c4",
   "metadata": {},
   "source": [
    "1에서 20까지를 key, 1에서 20까지의 거듭제곱을 value로 D구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23351a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 2, 2: 4, 3: 6, 4: 8, 5: 10, 6: 12, 7: 14, 8: 16, 9: 18, 10: 20, 11: 22, 12: 24, 13: 26, 14: 28, 15: 30, 16: 32, 17: 34, 18: 36, 19: 38, 20: 40}\n"
     ]
    }
   ],
   "source": [
    "D = {               }\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17224ab",
   "metadata": {},
   "source": [
    "단어를 입력하면 단어의 스펠을 key, 스펠의 개수를 value로 D구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a7d97e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n",
      "{'H': 1, 'e': 1, 'l': 3, 'o': 2, ' ': 1, 'w': 1, 'r': 1, 'd': 1}\n"
     ]
    }
   ],
   "source": [
    "word = input()\n",
    "L = list(word)\n",
    "D = {            for ch in L}\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33eed45",
   "metadata": {},
   "source": [
    "2024년도에 대해 날짜를 '월/일'의 형식으로 입력받아서 해당 날짜까지의 총 일수를 출력해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b6e7372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ex)4/20:5/13\n",
      "total days: 134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "date = input(\"(ex)4/20:\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073804b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41db2509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38bd62b4",
   "metadata": {},
   "source": [
    "# NLP : 자연어 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa8bb234",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"Nineteen Eighty-Four makes depressing but essential reading. \n",
    "Published in 1949, \n",
    "it’s the author’s vision of a dystopian future dominated by totalitarian state surveillance, mind control and perpetual war. \n",
    "At the centre of the novel is Winston, \n",
    "whose job is to rewrite old news stories so that they toe the party line, \n",
    "whom we follow in his quest for rebellion against the government he works for. \n",
    "Its memorable opening line sets the unsettling tone for the rest of this uncomfortable novel\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e7f420",
   "metadata": {},
   "source": [
    "특수문자 없애기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f2ed687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nineteen EightyFour makes depressing but essential reading \n",
      "Published in 1949 \n",
      "its the authors vision of a dystopian future dominated by totalitarian state surveillance mind control and perpetual war \n",
      "At the centre of the novel is Winston \n",
      "whose job is to rewrite old news stories so that they toe the party line \n",
      "whom we follow in his quest for rebellion against the government he works for \n",
      "Its memorable opening line sets the unsettling tone for the rest of this uncomfortable novel\n"
     ]
    }
   ],
   "source": [
    "s1 = \n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b5ebb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nineteen eightyfour makes depressing but essential reading \n",
      "published in 1949 \n",
      "its the authors vision of a dystopian future dominated by totalitarian state surveillance mind control and perpetual war \n",
      "at the centre of the novel is winston \n",
      "whose job is to rewrite old news stories so that they toe the party line \n",
      "whom we follow in his quest for rebellion against the government he works for \n",
      "its memorable opening line sets the unsettling tone for the rest of this uncomfortable novel\n"
     ]
    }
   ],
   "source": [
    "s2 = \n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05085602",
   "metadata": {},
   "source": [
    "bow(bag of words) 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa29f425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nineteen': 1, 'eightyfour': 1, 'makes': 1, 'depressing': 1, 'but': 1, 'essential': 1, 'reading': 1, 'published': 1, 'in': 2, '1949': 1, 'its': 2, 'the': 7, 'authors': 1, 'vision': 1, 'of': 3, 'a': 1, 'dystopian': 1, 'future': 1, 'dominated': 1, 'by': 1, 'totalitarian': 1, 'state': 1, 'surveillance': 1, 'mind': 1, 'control': 1, 'and': 1, 'perpetual': 1, 'war': 1, 'at': 1, 'centre': 1, 'novel': 2, 'is': 2, 'winston': 1, 'whose': 1, 'job': 1, 'to': 1, 'rewrite': 1, 'old': 1, 'news': 1, 'stories': 1, 'so': 1, 'that': 1, 'they': 1, 'toe': 1, 'party': 1, 'line': 2, 'whom': 1, 'we': 1, 'follow': 1, 'his': 1, 'quest': 1, 'for': 3, 'rebellion': 1, 'against': 1, 'government': 1, 'he': 1, 'works': 1, 'memorable': 1, 'opening': 1, 'sets': 1, 'unsettling': 1, 'tone': 1, 'rest': 1, 'this': 1, 'uncomfortable': 1}\n"
     ]
    }
   ],
   "source": [
    "L = s2.split()\n",
    "bow = {                     }\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87392ffb",
   "metadata": {},
   "source": [
    "많은 데이터의 bow구성 시 속도 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3ad4a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nineteen': 1, 'eightyfour': 1, 'makes': 1, 'depressing': 1, 'but': 1, 'essential': 1, 'reading': 1, 'published': 1, 'in': 2, '1949': 1, 'its': 2, 'the': 7, 'authors': 1, 'vision': 1, 'of': 3, 'a': 1, 'dystopian': 1, 'future': 1, 'dominated': 1, 'by': 1, 'totalitarian': 1, 'state': 1, 'surveillance': 1, 'mind': 1, 'control': 1, 'and': 1, 'perpetual': 1, 'war': 1, 'at': 1, 'centre': 1, 'novel': 2, 'is': 2, 'winston': 1, 'whose': 1, 'job': 1, 'to': 1, 'rewrite': 1, 'old': 1, 'news': 1, 'stories': 1, 'so': 1, 'that': 1, 'they': 1, 'toe': 1, 'party': 1, 'line': 2, 'whom': 1, 'we': 1, 'follow': 1, 'his': 1, 'quest': 1, 'for': 3, 'rebellion': 1, 'against': 1, 'government': 1, 'he': 1, 'works': 1, 'memorable': 1, 'opening': 1, 'sets': 1, 'unsettling': 1, 'tone': 1, 'rest': 1, 'this': 1, 'uncomfortable': 1}\n"
     ]
    }
   ],
   "source": [
    "bow = {}\n",
    "for token in L:\n",
    "    \n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aff3187",
   "metadata": {},
   "source": [
    "정규식으로 특수문자 제거하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f3b8a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nineteen Eighty Four makes depressing but essential reading   Published in 1949   it s the author s vision of a dystopian future dominated by totalitarian state surveillance  mind control and perpetual war   At the centre of the novel is Winston   whose job is to rewrite old news stories so that they toe the party line   whom we follow in his quest for rebellion against the government he works for   Its memorable opening line sets the unsettling tone for the rest of this uncomfortable novel\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "removechr = re.compile(\"[\\W_]\")\n",
    "s3 = removechr.sub(' ',s)\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e72d79b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e480569",
   "metadata": {},
   "source": [
    "## 영어 NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9abeeed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Obtaining dependency information for spacy from https://files.pythonhosted.org/packages/9d/0e/fe7fcae4e14b82fe8feefb7be2cd76f880d5e994ce5c1c159a47b89fd2cc/spacy-3.7.6-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading spacy-3.7.6-cp311-cp311-win_amd64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Obtaining dependency information for spacy-legacy<3.1.0,>=3.0.11 from https://files.pythonhosted.org/packages/c3/55/12e842c70ff8828e34e543a2c7176dac4da006ca6901c9e8b43efab8bc6b/spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Obtaining dependency information for spacy-loggers<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/33/78/d1a1a026ef3af911159398c939b1509d5c36fe524c7b644f34a5146c4e16/spacy_loggers-1.0.5-py3-none-any.whl.metadata\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Obtaining dependency information for murmurhash<1.1.0,>=0.28.0 from https://files.pythonhosted.org/packages/71/46/af01a20ec368bd9cb49a1d2df15e3eca113bbf6952cc1f2a47f1c6801a7f/murmurhash-1.0.10-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Obtaining dependency information for cymem<2.1.0,>=2.0.2 from https://files.pythonhosted.org/packages/c1/c3/dd044e6f62a3d317c461f6f0c153c6573ed13025752d779e514000c15dd2/cymem-2.0.8-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Obtaining dependency information for preshed<3.1.0,>=3.0.2 from https://files.pythonhosted.org/packages/e4/fc/78cdbdb79f5d6d45949e72c32445d6c060977ad50a1dcfc0392622165f7c/preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy)\n",
      "  Obtaining dependency information for thinc<8.3.0,>=8.2.2 from https://files.pythonhosted.org/packages/5e/0e/5e7b24e046e0725eafc37ded0cd9bfaf789efb894101a7aca8a73dba81de/thinc-8.2.5-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading thinc-8.2.5-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Obtaining dependency information for wasabi<1.2.0,>=0.9.1 from https://files.pythonhosted.org/packages/06/7c/34330a89da55610daa5f245ddce5aab81244321101614751e7537f125133/wasabi-1.1.3-py3-none-any.whl.metadata\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Obtaining dependency information for srsly<3.0.0,>=2.4.3 from https://files.pythonhosted.org/packages/eb/f5/e3f29993f673d91623df6413ba64e815dd2676fd7932cbc5e7347402ddae/srsly-2.4.8-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Obtaining dependency information for catalogue<2.1.0,>=2.0.6 from https://files.pythonhosted.org/packages/9e/96/d32b941a501ab566a16358d68b6eb4e4acc373fab3c3c4d7d9e649f7b4bb/catalogue-2.0.10-py3-none-any.whl.metadata\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Obtaining dependency information for weasel<0.5.0,>=0.1.0 from https://files.pythonhosted.org/packages/2a/87/abd57374044e1f627f0a905ac33c1a7daab35a3a815abfea4e1bafd3fdb1/weasel-0.4.1-py3-none-any.whl.metadata\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Obtaining dependency information for typer<1.0.0,>=0.3.0 from https://files.pythonhosted.org/packages/a8/2b/886d13e742e514f704c33c4caa7df0f3b89e5a25ef8db02aa9ca3d9535d5/typer-0.12.5-py3-none-any.whl.metadata\n",
      "  Downloading typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (23.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Obtaining dependency information for langcodes<4.0.0,>=3.2.0 from https://files.pythonhosted.org/packages/58/70/4058ab0ebb082b18d06888e711baed7f33354a5e0b363bb627586d8c323a/langcodes-3.4.0-py3-none-any.whl.metadata\n",
      "  Downloading langcodes-3.4.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (1.24.3)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Obtaining dependency information for language-data>=1.2 from https://files.pythonhosted.org/packages/12/5f/139464da89c49afcc8bb97ebad48818a535220ce01b1f24c61fb80dbe4d0/language_data-1.2.0-py3-none-any.whl.metadata\n",
      "  Downloading language_data-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy)\n",
      "  Obtaining dependency information for blis<0.8.0,>=0.7.8 from https://files.pythonhosted.org/packages/2f/09/da0592c74560cc33396504698122f7a56747c82a5e072ca7d2c3397898e1/blis-0.7.11-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading blis-0.7.11-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy)\n",
      "  Obtaining dependency information for confection<1.0.0,>=0.0.1 from https://files.pythonhosted.org/packages/0c/00/3106b1854b45bd0474ced037dfe6b73b90fe68a68968cef47c23de3d43d2/confection-0.1.5-py3-none-any.whl.metadata\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.0.4)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Obtaining dependency information for shellingham>=1.3.0 from https://files.pythonhosted.org/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Obtaining dependency information for rich>=10.11.0 from https://files.pythonhosted.org/packages/b0/11/dadb85e2bd6b1f1ae56669c3e1f0410797f9605d752d68fb47b77f525b31/rich-13.8.1-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.8.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Obtaining dependency information for cloudpathlib<1.0.0,>=0.7.0 from https://files.pythonhosted.org/packages/4d/4e/f83794cb311019c385d061d9b7a9dc444c7023c5523c3f4161191221429c/cloudpathlib-0.19.0-py3-none-any.whl.metadata\n",
      "  Downloading cloudpathlib-0.19.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Collecting marisa-trie>=0.7.7 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Obtaining dependency information for marisa-trie>=0.7.7 from https://files.pythonhosted.org/packages/61/28/b93cd14cd422be8fc091bd454dd48edbf0c2333111183db38c8e5a13e468/marisa_trie-1.2.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading marisa_trie-1.2.0-cp311-cp311-win_amd64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
      "Downloading spacy-3.7.6-cp311-cp311-win_amd64.whl (12.1 MB)\n",
      "   ---------------------------------------- 0.0/12.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/12.1 MB 8.1 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.9/12.1 MB 9.9 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.5/12.1 MB 10.3 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.2/12.1 MB 11.6 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.8/12.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.8/12.1 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.9/12.1 MB 14.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.1/12.1 MB 16.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.5/12.1 MB 15.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.5/12.1 MB 14.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.8/12.1 MB 13.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.2/12.1 MB 12.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.6/12.1 MB 12.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.2/12.1 MB 12.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.3/12.1 MB 13.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.9/12.1 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.1/12.1 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.1/12.1 MB 15.6 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.4.0-py3-none-any.whl (182 kB)\n",
      "   ---------------------------------------- 0.0/182.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 182.0/182.0 kB 10.7 MB/s eta 0:00:00\n",
      "Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl (122 kB)\n",
      "   ---------------------------------------- 0.0/122.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 122.3/122.3 kB 7.5 MB/s eta 0:00:00\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl (479 kB)\n",
      "   ---------------------------------------- 0.0/479.7 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 225.3/479.7 kB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 479.7/479.7 kB 6.0 MB/s eta 0:00:00\n",
      "Downloading thinc-8.2.5-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------  1.5/1.5 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 23.3 MB/s eta 0:00:00\n",
      "Downloading typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "   ---------------------------------------- 0.0/47.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 47.3/47.3 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.3/50.3 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading blis-0.7.11-cp311-cp311-win_amd64.whl (6.6 MB)\n",
      "   ---------------------------------------- 0.0/6.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/6.6 MB 2.4 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.2/6.6 MB 2.2 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.2/6.6 MB 1.9 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.4/6.6 MB 2.2 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.8/6.6 MB 3.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.9/6.6 MB 6.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.9/6.6 MB 12.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.1/6.6 MB 16.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.6/6.6 MB 15.6 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.19.0-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.4/49.4 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.2.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 2.4/5.4 MB 74.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.4 MB 65.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.4/5.4 MB 57.2 MB/s eta 0:00:00\n",
      "Downloading rich-13.8.1-py3-none-any.whl (241 kB)\n",
      "   ---------------------------------------- 0.0/241.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 241.6/241.6 kB 14.5 MB/s eta 0:00:00\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading marisa_trie-1.2.0-cp311-cp311-win_amd64.whl (152 kB)\n",
      "   ---------------------------------------- 0.0/152.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 152.6/152.6 kB ? eta 0:00:00\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, shellingham, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, srsly, rich, preshed, language-data, typer, langcodes, confection, weasel, thinc, spacy\n",
      "Successfully installed blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.19.0 confection-0.1.5 cymem-2.0.8 langcodes-3.4.0 language-data-1.2.0 marisa-trie-1.2.0 murmurhash-1.0.10 preshed-3.0.9 rich-13.8.1 shellingham-1.5.4 spacy-3.7.6 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.5 typer-0.12.5 wasabi-1.1.3 weasel-0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dae2c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99ea290b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the small English model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Sample text\u001b[39;00m\n\u001b[0;32m      5\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApple is looking at buying U.K. startup for $1 billion.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spacy' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the small English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26b8fd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.8 MB 682.7 kB/s eta 0:00:19\n",
      "     ---------------------------------------- 0.1/12.8 MB 1.2 MB/s eta 0:00:11\n",
      "     --- ------------------------------------ 1.2/12.8 MB 9.3 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 4.9/12.8 MB 28.3 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 8.2/12.8 MB 37.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 11.5/12.8 MB 73.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 65.2 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 50.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.3)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.8.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.0)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59320d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:\n",
      "Apple | Lemma: Apple | POS: PROPN | Dep: nsubj | Stopword: False\n",
      "is | Lemma: be | POS: AUX | Dep: aux | Stopword: True\n",
      "looking | Lemma: look | POS: VERB | Dep: ROOT | Stopword: False\n",
      "at | Lemma: at | POS: ADP | Dep: prep | Stopword: True\n",
      "buying | Lemma: buy | POS: VERB | Dep: pcomp | Stopword: False\n",
      "U.K. | Lemma: U.K. | POS: PROPN | Dep: dobj | Stopword: False\n",
      "startup | Lemma: startup | POS: NOUN | Dep: dep | Stopword: False\n",
      "for | Lemma: for | POS: ADP | Dep: prep | Stopword: True\n",
      "$ | Lemma: $ | POS: SYM | Dep: quantmod | Stopword: False\n",
      "1 | Lemma: 1 | POS: NUM | Dep: compound | Stopword: False\n",
      "billion | Lemma: billion | POS: NUM | Dep: pobj | Stopword: False\n",
      ". | Lemma: . | POS: PUNCT | Dep: punct | Stopword: False\n",
      "\n",
      "Named Entities:\n",
      "Apple | Label: ORG | Explanation: Companies, agencies, institutions, etc.\n",
      "U.K. | Label: GPE | Explanation: Countries, cities, states\n",
      "$1 billion | Label: MONEY | Explanation: Monetary values, including unit\n",
      "\n",
      "Part-of-speech tags:\n",
      "Apple: PROPN, proper noun\n",
      "is: AUX, auxiliary\n",
      "looking: VERB, verb\n",
      "at: ADP, adposition\n",
      "buying: VERB, verb\n",
      "U.K.: PROPN, proper noun\n",
      "startup: NOUN, noun\n",
      "for: ADP, adposition\n",
      "$: SYM, symbol\n",
      "1: NUM, numeral\n",
      "billion: NUM, numeral\n",
      ".: PUNCT, punctuation\n",
      "\n",
      "Dependency Parsing:\n",
      "Apple -> looking (dependency: nsubj)\n",
      "is -> looking (dependency: aux)\n",
      "looking -> looking (dependency: ROOT)\n",
      "at -> looking (dependency: prep)\n",
      "buying -> at (dependency: pcomp)\n",
      "U.K. -> buying (dependency: dobj)\n",
      "startup -> looking (dependency: dep)\n",
      "for -> startup (dependency: prep)\n",
      "$ -> billion (dependency: quantmod)\n",
      "1 -> billion (dependency: compound)\n",
      "billion -> for (dependency: pobj)\n",
      ". -> looking (dependency: punct)\n"
     ]
    }
   ],
   "source": [
    "# Load the small English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample text\n",
    "text = \"Apple is looking at buying U.K. startup for $1 billion.\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Tokenization\n",
    "print(\"Tokens:\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text} | Lemma: {token.lemma_} | POS: {token.pos_} | Dep: {token.dep_} | Stopword: {token.is_stop}\")\n",
    "\n",
    "# Named Entity Recognition (NER)\n",
    "print(\"\\nNamed Entities:\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text} | Label: {ent.label_} | Explanation: {spacy.explain(ent.label_)}\")\n",
    "\n",
    "# Part-of-speech Tagging\n",
    "print(\"\\nPart-of-speech tags:\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text}: {token.pos_}, {spacy.explain(token.pos_)}\")\n",
    "\n",
    "# Dependency Parsing\n",
    "print(\"\\nDependency Parsing:\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text} -> {token.head.text} (dependency: {token.dep_})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064be2aa",
   "metadata": {},
   "source": [
    "이 문장에서:\n",
    "\n",
    "Token: Apple — 문장에서의 단어 또는 구 (여기서는 \"Apple\").\n",
    "Lemma: Apple — 해당 단어의 기본형 또는 원형(lemma). \"Apple\"은 고유명사이므로 기본형과 형태가 동일합니다.\n",
    "POS (Part of Speech): PROPN — 품사로서 고유명사(proper noun)를 의미합니다. \"Apple\"은 특정 회사 이름이므로 고유명사입니다.\n",
    "Dep (Dependency): nsubj — 문법적 의존 관계에서 주어(nominal subject)를 나타냅니다. 여기서는 \"Apple\"이 문장의 주어 역할을 한다는 의미입니다.\n",
    "Stopword: False — stopword는 분석에 있어서 중요하지 않은 일반적인 단어를 의미합니다. 여기서 \"Apple\"은 중요한 단어이므로 stopword가 아니며, False가 출력되었습니다.\n",
    "따라서 이 정보는 주어진 문장에서 \"Apple\"이라는 단어가 고유명사로, 문장의 주어 역할을 하며 분석에 중요한 단어임을 나타냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e797b9ca",
   "metadata": {},
   "source": [
    "Common POS Tags\n",
    "NOUN (noun): A word that represents a person, place, thing, or idea.\n",
    " Example: dog, car, happiness\n",
    " Sentence: The dog barked loudly.\n",
    "\n",
    "PROPN (proper noun): A specific name for a person, place, or organization, always capitalized.\n",
    " Example: London, Microsoft\n",
    " Sentence: I visited London last summer. \n",
    " \n",
    "VERB (verb): A word that describes an action, occurrence, or state of being.\n",
    " Example: run, is, have\n",
    " Sentence: She runs every morning.  \n",
    " \n",
    "ADJ (adjective): A word that describes or modifies a noun.\n",
    " Example: beautiful, fast\n",
    " Sentence: He drives a fast car.\n",
    "\n",
    "ADV (adverb): A word that modifies a verb, adjective, or other adverbs. It often describes how something is done.\n",
    " Example: quickly, very\n",
    " Sentence: She runs quickly.\n",
    "\n",
    "PRON (pronoun): A word used in place of a noun to avoid repetition.\n",
    " Example: he, she, they\n",
    " Sentence: John loves pizza. He eats it often. \n",
    "\n",
    "DET (determiner): A word that introduces a noun and specifies it as known or unknown. \n",
    " Example: a, the, this \n",
    " Sentence: She bought a book.\n",
    " \n",
    "ADP (adposition): A word that shows the relationship of a noun or pronoun to another word, typically prepositions. \n",
    " Example: in, on, at\n",
    " Sentence: The book is on the table.\n",
    "\n",
    "CONJ (conjunction): A word that connects phrases, clauses, or words.\n",
    " Example: and, but, or\n",
    " Sentence: I like pizza and pasta.\n",
    "\n",
    "CCONJ (coordinating conjunction): A conjunction that connects words, phrases, or clauses that are equal in structure.\n",
    " Example: and, but, or\n",
    " Sentence: She plays soccer and tennis.\n",
    "\n",
    "SCONJ (subordinating conjunction): A conjunction that introduces a subordinate clause.\n",
    " Example: because, although\n",
    " Sentence: She left early because she was tired.\n",
    "\n",
    "NUM (numeral): A word that expresses a number or order.\n",
    " Example: one, two, third\n",
    " Sentence: I have two cats.\n",
    "\n",
    "PART (particle): A functional word that doesn’t fit neatly into other categories, often associated with verbs to form phrasal verbs.\n",
    " Example: to (in \"to go\"), up (in \"give up\")\n",
    " Sentence: She had to give up smoking.\n",
    "\n",
    "INTJ (interjection): A word that expresses emotion or a reaction, often  standing alone.\n",
    " Example: wow, ouch\n",
    " Sentence: Wow, that’s amazing!\n",
    " \n",
    "SYM (symbol): A symbol or punctuation mark.\n",
    " Example: &, #\n",
    " Sentence: Use the & symbol.\n",
    "\n",
    "PUNCT (punctuation): Punctuation marks. \n",
    " Example: ., !, ,\n",
    " Sentence: She said, “Hello!”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5262081",
   "metadata": {},
   "source": [
    "## Korean NLP Model (KoNLPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "409ee2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in c:\\users\\user\\anaconda3\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from konlpy) (1.5.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from konlpy) (4.9.3)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from konlpy) (1.24.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (23.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566c7795",
   "metadata": {},
   "source": [
    "### Example with KoNLPy (Kkma or Okt):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40c136f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kkma Tokenization: ['안녕', '하', '세요', '.', '학생', '여러분', ',', '부산', '소마', '이', '고', '학생', '이', 'ㅂ니다', '.']\n",
      "Okt Tokenization: ['안녕하세요', '.', '학생', '여러분', ',', '부산', '소마', '고', '학생', '입니다', '.']\n",
      "Kkma POS Tagging: [('안녕', 'NNG'), ('하', 'XSV'), ('세요', 'EFN'), ('.', 'SF'), ('학생', 'NNG'), ('여러분', 'NP'), (',', 'SP'), ('부산', 'NNG'), ('소마', 'NNG'), ('이', 'VCP'), ('고', 'ECE'), ('학생', 'NNG'), ('이', 'VCP'), ('ㅂ니다', 'EFN'), ('.', 'SF')]\n",
      "Okt POS Tagging: [('안녕하세요', 'Adjective'), ('.', 'Punctuation'), ('학생', 'Noun'), ('여러분', 'Noun'), (',', 'Punctuation'), ('부산', 'Noun'), ('소마', 'Noun'), ('고', 'Josa'), ('학생', 'Noun'), ('입니다', 'Adjective'), ('.', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Kkma, Okt\n",
    "\n",
    "# Initialize the tokenizer\n",
    "kkma = Kkma()\n",
    "okt = Okt()\n",
    "\n",
    "# Sample Korean text\n",
    "text = \"안녕하세요. 학생 여러분, 부산 소마고 학생입니다.\"\n",
    "\n",
    "# Tokenization using Kkma\n",
    "tokens_kkma = kkma.morphs(text)\n",
    "print(\"Kkma Tokenization:\", tokens_kkma)\n",
    "\n",
    "# Tokenization using Okt\n",
    "tokens_okt = okt.morphs(text)\n",
    "print(\"Okt Tokenization:\", tokens_okt)\n",
    "\n",
    "# POS tagging using Kkma\n",
    "pos_tags_kkma = kkma.pos(text)\n",
    "print(\"Kkma POS Tagging:\", pos_tags_kkma)\n",
    "\n",
    "# POS tagging using Okt\n",
    "pos_tags_okt = okt.pos(text)\n",
    "print(\"Okt POS Tagging:\", pos_tags_okt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e95272c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Nouns:\n",
      "['학생', '여러분', '부산', '소마', '학생']\n",
      "\n",
      "Extracted Phrases:\n",
      "['학생', '학생 여러분', '부산', '부산 소마', '여러분', '소마']\n",
      "\n",
      "Normalized Text:\n",
      "안녕하세요. 학생 여러분, 부산 소마고 학생입니다.\n"
     ]
    }
   ],
   "source": [
    "# Noun Extraction\n",
    "nouns = okt.nouns(text)\n",
    "print(\"\\nExtracted Nouns:\")\n",
    "print(nouns)\n",
    "\n",
    "# Phrase extraction\n",
    "phrases = okt.phrases(text)\n",
    "print(\"\\nExtracted Phrases:\")\n",
    "print(phrases)\n",
    "\n",
    "# Normalize the text (useful for informal text)\n",
    "normalized_text = okt.normalize(text)\n",
    "print(\"\\nNormalized Text:\")\n",
    "print(normalized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb88bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bfa8032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'안녕하세요': 1, '.': 2, '학생': 2, '여러분': 1, ',': 1, '부산': 1, '소마': 1, '고': 1, '입니다': 1}\n"
     ]
    }
   ],
   "source": [
    "Bow = {}\n",
    "for \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712367cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
